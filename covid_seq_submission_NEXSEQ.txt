# code for NEXSEQ_033 - batch8

# I make a new directory for each batch of submissions
# Set unix/linux variable path for wd - so can reuse code across projects
cur_wd="/home/mandy_waters/batch8_submit"

# cd into cur_wd and make directories
mkdir download_fasta
mkdir sequence_data
mkdir metadata

# In cur_wd make a file called project_list.txt that lists the projects to be submitted - with one project per line (I used vim to add, but users can use text editor if preferred)
NEXSEQ_033

# Pull metadata from Google Drive - pull results*.tsv files for all projects into 'metadata' dir

# Download latest rerun sheet from google drive

# generate gisaid and biosample metadata using gisaid_ncbi_biosample_metadata_formatting.R - I write these files file the 'metadata' dir
Rscript ~/scripts/git_repo/seq-submission-metadata-R/gisaid_ncbi_biosample_metadata_formatting.R -m ${cur_wd}/metadata -s mandy.waters -f batch8_gisaid_inital_upload.fa -t "Illumina NextSeq" -r /home/mandy_waters/Downloads/rerun_samples_12Sep2021.tsv

# make file to only pull consensus sequences >50% coverage and filtered for reruns
cut -f 1,3 fasta_rename_accession_to_gisaid_id.tsv | grep -v '^accesion' | sed 's/CO-CDPHE-//g' > consensus_fasta_to_pull.tsv

# Get list of files with >= 50% coverage and rerun samples removed for seqtk
cut -f 1 ncbi_biosample_submission*_metadata.tsv > fasta_headers_50cov.txt

# pull consensus fastas only for samples >50% coverage and rerun samples removed to 'download_fasta' - this is a bit slow, but it selectively pulls the fasta files
while read acc proj; do gsutil -m cp gs://covid_terra/${proj}/terra_outputs/assemblies/${acc}_consensus_renamed.fa .; done < ${cur_wd}/metadata/consensus_fasta_to_pull.tsv

# Concat all downloaded fastas in 'download_fasta' dir
cat *_consensus_renamed.fa > raw_concat.fa

# Delete the original & individ files
rm *_consensus_renamed.fa

# clone and create new conda environment
conda activate indel_finder_env

# Run indel finder
/home/mandy_waters/scripts/sars-cov-2_indel_finder/indel_finder.py -i ${cur_wd}/download_fasta/raw_concat.fa -o ${cur_wd}/download_fasta --ref_path /home/mandy_waters/ref_seq/reference.fasta --prefix batch8

# Pulling bam files for samples with insertions - making file to pull them
grep '+' *indels.csv | cut -f 1 -d ',' > indel_finder_insertion_accession_names.txt
grep '+' *indels.csv > coverage_info_insertions.csv
sort -t , -k 3 coverage_info_insertions.csv

# Pulling project and accession information from the sequencing results file
while read name; do grep $name ${cur_wd}/metadata/results_*.tsv >> failed_to_pull_bam_files.txt; done < indel_finder_insertion_accession_names.txt 

# Getting only the information we need
cut -f 28-29 failed_to_pull_bam_files.txt > project_accessions_failed.txt

# pull bam files from google buckets
while read project acc; do gsutil cp gs://covid_terra/${project}/terra_outputs/alignments/${acc}*.bam .; done < project_accessions_failed.txt

# index the bam files to load into IGV
for i in *.bam; do samtools index $i; done

# Rename seq names with GISAID format
awk -F, 'FNR==NR {f2[$1]=$2;next} $2 in f2 {$2=f2[$2]}1' ${cur_wd}/metadata/fasta_rename_accession_to_gisaid_id.csv FS='>' OFS='>' batch8.alignment.fasta > post_indel_concat_gisaid_format.fa

# Removing dashes from the MSA from indel finder as VADR doesn't accept dashes
sed '/^>/! s/-//g' post_indel_concat_gisaid_format.fa > post_indel_concat_gisaid_format_nodash.fa

# Run VADR 1.3 on entire dataset
docker run --rm=True -v $PWD:/data -u $(id -u):$(id -g) staphb/vadr:1.3 v-annotate.pl --split --cpu 8 --glsearch -s -r --nomisc --mkey sarscov2 --lowsim5seq 2 --lowsim3seq 2 --alt_fail lowscore,insertnn,deletinn post_indel_concat_gisaid_format_nodash.fa vadr_run
______

# Pulling samples for IGV in vadr_run
sed 's/hCoV-19\/USA\/CO-CDPHE-//g' vadr_run.vadr.fail.list > accessions_failed_to_pull.csv
sed -i -e 's/\/202.*//g' accessions_failed_to_pull.csv 
while read name; do grep $name ${cur_wd}/metadata/results*.tsv >> failed_to_pull_bam_files.txt; done < accessions_failed_to_pull.csv
cut -f 28-29 failed_to_pull_bam_files.txt > project_accessions_failed.txt

while read project acc; do gsutil cp gs://covid_terra/${project}/terra_outputs/alignments/${acc}*.bam .; done < project_accessions_failed.txt

for i in *.bam; do samtools index $i; done

# Use Aliview to see and correct sequences based on IGV
# Read in: 
# Write out: 

# Files uploaded to GISAID
# metadata: 
# fasta: 

# Submit biosample metadata


# download file from Biosample - from email BioSampleObjects.txt to 'metadata' dir

# Create metadata for SRA
Rscript ncbi_sra_metadata_formatting.R -p ${cur_wd}/metadata -t "Illumina NextSeq"

